{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surface[　]\tbase[　]\tpos[記号]\tpos1[空白]\n",
      "surface[吾輩]\tbase[吾輩]\tpos[名詞]\tpos1[代名詞]\n",
      "surface[は]\tbase[は]\tpos[助詞]\tpos1[係助詞]\n",
      "surface[猫]\tbase[猫]\tpos[名詞]\tpos1[一般]\n",
      "surface[で]\tbase[だ]\tpos[助動詞]\tpos1[*]\n",
      "surface[ある]\tbase[ある]\tpos[助動詞]\tpos1[*]\n",
      "surface[。]\tbase[。]\tpos[記号]\tpos1[句点]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "class Morph:\n",
    "    \n",
    "    def __init__(self, surface, base, pos, pos1):\n",
    "        '''初期化'''\n",
    "        self.surface = surface\n",
    "        self.base = base\n",
    "        self.pos = pos\n",
    "        self.pos1 = pos1\n",
    "\n",
    "    def __str__(self):\n",
    "        '''オブジェクトの文字列表現'''\n",
    "        return 'surface[{}]\\tbase[{}]\\tpos[{}]\\tpos1[{}]'.format(self.surface, self.base, self.pos, self.pos1)\n",
    "\n",
    "\n",
    "def neco_lines():\n",
    "    \n",
    "    with open('neko.txt.cabocha') as fcabo:\n",
    "\n",
    "        morphs = []\n",
    "        for line in fcabo:\n",
    "\n",
    "            # 1文の終了判定\n",
    "            if line == 'EOS\\n':\n",
    "                yield morphs\n",
    "                morphs = []\n",
    "\n",
    "            else:\n",
    "                # *はスキップ\n",
    "                if line[0] == '*':\n",
    "                    continue\n",
    "\n",
    "                # 表層形はtab区切り、それ以外は','区切りでバラす\n",
    "                cols = line.split('\\t')\n",
    "                res_cols = cols[1].split(',')\n",
    "\n",
    "                # Morph作成、リストに追加\n",
    "                morphs.append(Morph(\n",
    "                    cols[0],        # surface\n",
    "                    res_cols[6],    # base\n",
    "                    res_cols[0],    # pos\n",
    "                    res_cols[1]     # pos1\n",
    "                ))\n",
    "\n",
    "        raise StopIteration\n",
    "\n",
    "\n",
    "# 1文ずつリスト作成\n",
    "for i, morphs in enumerate(neco_lines(), 1):\n",
    "\n",
    "    # 3文目を表示\n",
    "    if i == 3:\n",
    "        for morph in morphs:\n",
    "            print(morph)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] 吾輩は\tsrcs[]\tdst[5]\n",
      "[1] ここで\tsrcs[]\tdst[2]\n",
      "[2] 始めて\tsrcs[1]\tdst[3]\n",
      "[3] 人間という\tsrcs[2]\tdst[4]\n",
      "[4] ものを\tsrcs[3]\tdst[5]\n",
      "[5] 見た。\tsrcs[0, 4]\tdst[-1]\n"
     ]
    }
   ],
   "source": [
    "#40に加えて，文節を表すクラスChunkを実装せよ．\n",
    "#このクラスは形態素（Morphオブジェクト）のリスト（morphs），係り先文節インデックス番号（dst），\n",
    "#係り元文節インデックス番号のリスト（srcs）をメンバ変数に持つこととする．\n",
    "#さらに，入力テキストのCaboChaの解析結果を読み込み，１文をChunkオブジェクトのリストとして表現し，\n",
    "#8文目の文節の文字列と係り先を表示せよ．\n",
    "#第5章の残りの問題では，ここで作ったプログラムを活用せよ．\n",
    "\n",
    "import re\n",
    "\n",
    "class Morph:\n",
    "    \n",
    "    def __init__(self, surface, base, pos, pos1):\n",
    "        '''初期化'''\n",
    "        self.surface = surface\n",
    "        self.base = base\n",
    "        self.pos = pos\n",
    "        self.pos1 = pos1\n",
    "\n",
    "    def __str__(self):\n",
    "        '''オブジェクトの文字列表現'''\n",
    "        return 'surface[{}]\\tbase[{}]\\tpos[{}]\\tpos1[{}]'.format(self.surface, self.base, self.pos, self.pos1)\n",
    "\n",
    "class Chunk:\n",
    "    def __init__(self):\n",
    "        self.morphs=[]\n",
    "        self.srcs=[]\n",
    "        self.dst=-1\n",
    "        \n",
    "    def __str__(self):\n",
    "        surface=' '\n",
    "        for morph in self.morphs:\n",
    "            surface +=morph.surface\n",
    "        return '{}\\tsrcs{}\\tdst[{}]'.format(surface,self.srcs,self.dst)\n",
    "    \n",
    "        \n",
    "        \n",
    "\n",
    "def neco_lines():\n",
    "    '''「吾輩は猫である」の係り受け解析結果のジェネレータ\n",
    "    「吾輩は猫である」の係り受け解析結果を順次読み込んで、\n",
    "    1文ずつChunkクラスのリストを返す\n",
    "\n",
    "    戻り値：\n",
    "    1文のChunkクラスのリスト\n",
    "    '''\n",
    "    with open('neko.txt.cabocha') as fcabo:\n",
    "\n",
    "        chunks = dict()     # idxをkeyにChunkを格納\n",
    "        idx = -1\n",
    "\n",
    "        for line in fcabo:\n",
    "\n",
    "            # 1文の終了判定\n",
    "            if line == 'EOS\\n':\n",
    "\n",
    "                # Chunkのリストを返す\n",
    "                if len(chunks) > 0:\n",
    "\n",
    "                    # chunksをkeyでソートし、valueのみ取り出し\n",
    "                    sorted_tuple = sorted(chunks.items(), key=lambda x: x[0])\n",
    "                    yield list(zip(*sorted_tuple))[1]\n",
    "                    chunks.clear()\n",
    "\n",
    "                else:\n",
    "                    yield []\n",
    "\n",
    "            # 先頭が*の行は係り受け解析結果なので、Chunkを作成\n",
    "            elif line[0] == '*':\n",
    "\n",
    "                # Chunkのインデックス番号と係り先のインデックス番号取得\n",
    "                cols = line.split(' ')\n",
    "                idx = int(cols[1])\n",
    "                dst = int(re.search(r'(.*?)D', cols[2]).group(1))\n",
    "\n",
    "                # Chunkを生成（なければ）し、係り先のインデックス番号セット\n",
    "                if idx not in chunks:\n",
    "                    chunks[idx] = Chunk()\n",
    "                chunks[idx].dst = dst\n",
    "\n",
    "                # 係り先のChunkを生成（なければ）し、係り元インデックス番号追加\n",
    "                if dst != -1:\n",
    "                    if dst not in chunks:\n",
    "                        chunks[dst] = Chunk()\n",
    "                    chunks[dst].srcs.append(idx)\n",
    "\n",
    "            # それ以外の行は形態素解析結果なので、Morphを作りChunkに追加\n",
    "            else:\n",
    "\n",
    "                # 表層形はtab区切り、それ以外は','区切りでバラす\n",
    "                cols = line.split('\\t')\n",
    "                res_cols = cols[1].split(',')\n",
    "\n",
    "                # Morph作成、リストに追加\n",
    "                chunks[idx].morphs.append(\n",
    "                    Morph(\n",
    "                        cols[0],        # surface\n",
    "                        res_cols[6],    # base\n",
    "                        res_cols[0],    # pos\n",
    "                        res_cols[1]     # pos1\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        raise StopIteration\n",
    "\n",
    "\n",
    "# 1文ずつリスト作成\n",
    "for i, chunks in enumerate(neco_lines(), 1):\n",
    "\n",
    "    # 8文目を表示\n",
    "    if i == 8:\n",
    "        for j, chunk in enumerate(chunks):\n",
    "            print('[{}]{}'.format(j, chunk))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#係り元の文節と係り先の文節のテキストをタブ区切り形式ですべて抽出せよ．\n",
    "#ただし，句読点などの記号は出力しないようにせよ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#名詞を含む文節が，動詞を含む文節に係るとき，これらをタブ区切り形式で抽出せよ．\n",
    "#ただし，句読点などの記号は出力しないようにせよ．\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#与えられた文の係り受け木を有向グラフとして可視化せよ．\n",
    "#可視化には，係り受け木をDOT言語に変換し，Graphvizを用いるとよい．また，\n",
    "#Pythonから有向グラフを直接的に可視化するには，pydotを使うとよい．\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
